{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8510cd",
   "metadata": {},
   "source": [
    "## 11. Flaky tests: causes and cures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f758996",
   "metadata": {},
   "source": [
    "A **flaky** test sometimes passes, sometimes fails with no code change. Root causes:\n",
    "* Hidden time assumptions (`sleep(0.1)`) → use explicit waits or free‐running clocks.\n",
    "* Randomness not seeded (`random.random()`) → set `PYTHONHASHSEED`, seed RNG.\n",
    "* External services / network latency → mock or retry.\n",
    "* Order dependence – tests mutate global state.\n",
    "\n",
    "Detection: run with `pytest -n auto --lf --maxfail=1 --reruns 3` in CI; quarantine & fix quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff022f25",
   "metadata": {},
   "source": [
    "```python\n",
    "import random, pytest\n",
    "def lucky():\n",
    "    return random.randint(0,1)\n",
    "def test_lucky():\n",
    "    random.seed(0)\n",
    "    assert lucky() == 1  # deterministic now\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d052ea7",
   "metadata": {},
   "source": [
    "### Quick check\n",
    "\n",
    "1. Race conditions often manifest as:\n",
    "  a. deterministic failures  b. intermittent failures\n",
    "\n",
    "2. True / False Setting PYTHONHASHSEED fixes order‐dependent dictionaries.\n",
    "\n",
    "<details><summary>Answer key</summary>\n",
    "\n",
    "1. **b**.\n",
    "2. **True** – forces repeatable hash order.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382ac70",
   "metadata": {},
   "source": [
    "## 12. Code coverage with `coverage.py` & `pytest-cov`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca049a3",
   "metadata": {},
   "source": [
    "`coverage run -m pytest` or `pytest --cov=src --cov-report=term-missing` measures which lines executed.\n",
    "* **Line coverage** – percentage of lines touched.\n",
    "* **Branch coverage** – covers if/else arms.\n",
    "Aim for risk‑based target (≈80%), but value lies in **what remains untested**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1555e",
   "metadata": {},
   "source": [
    "```bash\n",
    "pytest --cov=project --cov-report=html\n",
    "# opens htmlcov/index.html with colourised gaps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5aaea2",
   "metadata": {},
   "source": [
    "### Quick check\n",
    "\n",
    "1. Missing branch coverage might hide:\n",
    "  a. dead code  b. well‑tested paths only\n",
    "\n",
    "2. True / False 100 % coverage guarantees bug‑free code.\n",
    "\n",
    "<details><summary>Answer key</summary>\n",
    "\n",
    "1. **a**.\n",
    "2. **False** – tests could assert nothing.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4bbd3",
   "metadata": {},
   "source": [
    "## 13. Behaviour‑driven hints (Given‑When‑Then)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf86c6",
   "metadata": {},
   "source": [
    "BDD frames tests as **specifications** in business language:\n",
    "* **Given** context\n",
    "* **When** action\n",
    "* **Then** expected outcome\n",
    "\n",
    "Tools: `pytest-bdd`, `behave`. Keeps stakeholders engaged and clarifies intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38092a18",
   "metadata": {},
   "source": [
    "```python\n",
    "# test_login.feature\n",
    "Scenario: Successful login\n",
    "  Given I am on the login page\n",
    "  When I submit valid credentials\n",
    "  Then I should see the dashboard\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2c7bc",
   "metadata": {},
   "source": [
    "### Quick check\n",
    "\n",
    "1. BDD primarily targets:\n",
    "  a. developers only  b. dev + business\n",
    "\n",
    "2. True / False pytest can integrate BDD via plugins.\n",
    "\n",
    "<details><summary>Answer key</summary>\n",
    "\n",
    "1. **b**.\n",
    "2. **True**.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c0514",
   "metadata": {},
   "source": [
    "## 14. Property‑based testing with Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79efbe4f",
   "metadata": {},
   "source": [
    "Instead of hand‑picked examples, **Hypothesis** generates random inputs satisfying strategies and tries to falsify invariants. Finds edge cases humans miss.\n",
    "Key API: `@given(ints(), lists(ints()))` and `assume` / `reject`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477214a5",
   "metadata": {},
   "source": [
    "```python\n",
    "from hypothesis import given, strategies as st\n",
    "@given(st.lists(st.integers()))\n",
    "def test_rev_rev(xs):\n",
    "    assert list(reversed(list(reversed(xs)))) == xs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a411ccc5",
   "metadata": {},
   "source": [
    "### Quick check\n",
    "\n",
    "1. Hypothesis shrinks failing data to:\n",
    "  a. largest case  b. minimal counterexample\n",
    "\n",
    "2. True / False Property tests can replace all unit tests.\n",
    "\n",
    "<details><summary>Answer key</summary>\n",
    "\n",
    "1. **b**.\n",
    "2. **False** – complement, not replace.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f26840d",
   "metadata": {},
   "source": [
    "## 15. Performance benchmarks & profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8b609",
   "metadata": {},
   "source": [
    "`pytest-benchmark` measures wall‑time and compares to saved baseline. For deeper insight use `cProfile`, `snakeviz`, or `py-spy` flamegraphs.\n",
    "Micro‑benchmarks must run on quiet CPU; pin process with taskset or use CI perf machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf74ab3",
   "metadata": {},
   "source": [
    "```python\n",
    "# test_speed.py\n",
    "def fib(n):\n",
    "    a,b=0,1\n",
    "    for _ in range(n): a,b=b,a+b\n",
    "    return a\n",
    "def test_bench(benchmark):\n",
    "    benchmark(fib, 1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c41ce",
   "metadata": {},
   "source": [
    "### Quick check\n",
    "\n",
    "1. `pytest-benchmark` fails build if slower than baseline when flag:\n",
    "  a. --benchmark-autosave  b. --benchmark-fail=0%\n",
    "\n",
    "\n",
    "2. True / False `py-spy` injects without modifying source code.\n",
    "\n",
    "<details><summary>Answer key</summary>\n",
    "\n",
    "1. **b**.\n",
    "2. **True**.\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
